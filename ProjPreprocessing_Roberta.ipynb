{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O84mo4ysKWBQ",
    "outputId": "bad274b3-5424-4364-d2a5-bda5a34ec257"
   },
   "outputs": [],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install xmltodict --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "[0, 100, 190, 300, 127, 9231, 979, 65, 6, 142, 9, 5, 1575, 14, 24, 1523, 6, 101, 6, 939, 29665, 6, 23769, 2413, 22571, 6, 8247, 1971, 8, 55, 328, 2]\n",
      "['<s>', 'I', 'Ġeven', 'Ġgot', 'Ġmy', 'Ġteenage', 'Ġson', 'Ġone', ',', 'Ġbecause', 'Ġof', 'Ġthe', 'Ġfeatures', 'Ġthat', 'Ġit', 'Ġoffers', ',', 'Ġlike', ',', 'Ġi', 'Chat', ',', 'ĠPhot', 'ob', 'ooth', ',', 'Ġgarage', 'Ġband', 'Ġand', 'Ġmore', '!', '</s>']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-pos', 'O', 'O', 'O', 'O', 'O', 'O', 'B-pos', 'I-pos', 'O', 'B-pos', 'I-pos', 'I-pos', 'O', 'B-pos', 'I-pos', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "import re\n",
    "\n",
    "polarity_dict = {'positive':'pos', 'negative':'neg', 'neutral':'neu', 'conflict':'con'}\n",
    "\n",
    "def get_labels(sentence, tokens, aspect_list):\n",
    "  if len(aspect_list) == 0:\n",
    "    return ['O' for i in range(len(tokens))]\n",
    "\n",
    "  new_tokens = tokens[1:-1]\n",
    "  cur_pos = 0\n",
    "  cur_asp_idx = 0\n",
    "  ans = ['O']\n",
    "  for x in new_tokens:\n",
    "    cur_sub_word = x if x[:1]!='Ġ' else x[1:]\n",
    "    #pattern = re.compile(cur_sub_word)\n",
    "    #match = pattern.search(sentence, cur_pos)\n",
    "    #s,e = match.span()\n",
    "    s = sentence.find(cur_sub_word, cur_pos)\n",
    "    e = s + len(cur_sub_word)\n",
    "    if cur_asp_idx < len(aspect_list) and s >= aspect_list[cur_asp_idx]['start'] and s<aspect_list[cur_asp_idx]['end']:\n",
    "      cur_char = 'B' if ans[-1]=='O' else 'I'\n",
    "      ans.append(f'{cur_char}-{polarity_dict[aspect_list[cur_asp_idx][\"polarity\"]]}')\n",
    "    else:\n",
    "      ans.append('O')\n",
    "    if cur_asp_idx < len(aspect_list) and s >= aspect_list[cur_asp_idx]['end']:\n",
    "      cur_asp_idx += 1\n",
    "    cur_pos = e\n",
    "  ans.append('O')\n",
    "  return ans\n",
    "\n",
    "\n",
    "# my_sentence = \"I charge it at night and skip taking the cord with me because of the good battery life.\"\n",
    "# polarity = ['neutral', 'positive']\n",
    "# start_of_aspect = [41, 74]\n",
    "# end_of_aspect = [45, 86]\n",
    "# aspect_list = [{'polarity':'neutral', 'start':41, 'end':45}, {'polarity':'positive', 'start':74, 'end':86}]\n",
    "\n",
    "my_sentence = \"I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!\"\n",
    "polarity = ['positive']\n",
    "start_of_aspect = [46, 77, 84, 96]\n",
    "end_of_aspect = [54, 82, 94, 107]\n",
    "aspect_list = [{'polarity':'positive', 'start':46, 'end':54}, {'polarity':'positive', 'start':77, 'end':82},\n",
    "               {'polarity':'positive', 'start':84, 'end':94}, {'polarity':'positive', 'start':96, 'end':107}]\n",
    "\n",
    "print(len(my_sentence))\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "\n",
    "input_ids = tokenizer.encode(my_sentence)\n",
    "subwords = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "print(input_ids)\n",
    "print(subwords)\n",
    "labels = get_labels(my_sentence, subwords, aspect_list)\n",
    "print(labels)\n",
    "\n",
    "assert len(input_ids) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLI3YD14OChL",
    "outputId": "db05851a-96cb-4bb9-8f7d-22988bd3abb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3045/3045 [00:02<00:00, 1416.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"Laptop_Train_v2.xml\", \"r\", encoding=\"utf-8\") as f:\n",
    "  obj = xmltodict.parse(f.read())\n",
    "\n",
    "obj = obj['sentences']['sentence']\n",
    "out_sid = []\n",
    "out_tokens = []\n",
    "out_labels = []\n",
    "for x in tqdm(obj, total=len(obj)):\n",
    "  sentence = x['text']\n",
    "  sent_id = x['@id']\n",
    "  aspect_list = []\n",
    "  if 'aspectTerms' in x.keys():\n",
    "    aspects = x['aspectTerms']['aspectTerm']\n",
    "    if type(aspects) != list:\n",
    "      aspects = [aspects]\n",
    "    for a in aspects:\n",
    "      aspect_list.append({'polarity':a['@polarity'], 'start':int(a['@from']), 'end':int(a['@to'])})\n",
    "    aspect_list.sort(key=lambda x: x['start'])\n",
    "  input_ids = tokenizer.encode(sentence)\n",
    "  subwords = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "  \n",
    "  labels = get_labels(sentence, subwords, aspect_list)\n",
    "  # print(sentence)\n",
    "  # print(subwords)\n",
    "  # print(aspect_list)\n",
    "  # print(labels)\n",
    "  # print()\n",
    "  assert len(labels) == len(subwords)\n",
    "  out_sid.append(sent_id)\n",
    "  out_tokens.append(input_ids)\n",
    "  out_labels.append(labels)\n",
    "\n",
    "print('Writing to file...')\n",
    "df = pd.DataFrame()\n",
    "df['sid'] = out_sid\n",
    "df['token_ids'] = out_tokens\n",
    "df['labels'] = out_labels\n",
    "df.to_csv('preproc_roberta_14_laptop_train.csv', index=False)\n",
    "print('DONE')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ProjPreprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
