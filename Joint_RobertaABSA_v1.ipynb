{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RobertaABSA_v1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWanrpFwcoNd"
      },
      "source": [
        "# RoBERTa ABSA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p13WEYEHZ3Ds"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxDI8PHiY0As"
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.058251Z",
          "start_time": "2021-07-26T15:00:19.763155Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngel3XVFgZoR",
        "outputId": "47a216da-00dc-4f97-9cb5-87880c8c02fe"
      },
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers.trainer_utils import set_seed\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "set_seed(1234)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ5Lq-F8dWOk"
      },
      "source": [
        "## Import files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijbWbPSHZ2gG",
        "outputId": "ff8ac633-2465-4b8b-88ae-abfc5e88f935"
      },
      "source": [
        "rest14_train = pd.read_csv('preproc_roberta_14_restaurant_train.csv')\n",
        "rest14_train['token_ids'] = rest14_train['token_ids'].apply(eval)\n",
        "rest14_train['labels'] = rest14_train['labels'].apply(eval)\n",
        "l_train=rest14_train['labels'].tolist()\n",
        "max_len_train=max(len(i) for i in l_train)\n",
        "print(max_len_train)\n",
        "\n",
        "rest14_test = pd.read_csv('preproc_roberta_14_restaurant_test.csv')\n",
        "rest14_test['token_ids'] = rest14_test['token_ids'].apply(eval)\n",
        "rest14_test['labels'] = rest14_test['labels'].apply(eval)\n",
        "l_test=rest14_test['labels'].tolist()\n",
        "max_len_test=max(len(i) for i in l_test)\n",
        "print(max_len_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86\n",
            "71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIAfGZcDssaX",
        "outputId": "1be8cfdc-befd-4ffb-fcbf-5f71af78dead"
      },
      "source": [
        "lap14_train = pd.read_csv('preproc_roberta_14_laptop_train.csv')\n",
        "lap14_train['token_ids'] = lap14_train['token_ids'].apply(eval)\n",
        "lap14_train['labels'] = lap14_train['labels'].apply(eval)\n",
        "l_train=lap14_train['labels'].tolist()\n",
        "max_len_train=max(len(i) for i in l_train)\n",
        "print(max_len_train)\n",
        "\n",
        "lap14_test = pd.read_csv('preproc_roberta_14_laptop_test.csv')\n",
        "lap14_test['token_ids'] = lap14_test['token_ids'].apply(eval)\n",
        "lap14_test['labels'] = lap14_test['labels'].apply(eval)\n",
        "l_test=lap14_test['labels'].tolist()\n",
        "max_len_test=max(len(i) for i in l_test)\n",
        "print(max_len_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91\n",
            "84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQo9ZagOssUg",
        "outputId": "753548df-5f71-4745-aea2-73b43f4f27c6"
      },
      "source": [
        "rest16_train = pd.read_csv('preproc_roberta_16_restaurant_train.csv')\n",
        "rest16_train['token_ids'] = rest16_train['token_ids'].apply(eval)\n",
        "rest16_train['labels'] = rest16_train['labels'].apply(eval)\n",
        "l_train=rest16_train['labels'].tolist()\n",
        "max_len_train=max(len(i) for i in l_train)\n",
        "print(max_len_train)\n",
        "\n",
        "rest16_test = pd.read_csv('preproc_roberta_16_restaurant_test.csv')\n",
        "rest16_test['token_ids'] = rest16_test['token_ids'].apply(eval)\n",
        "rest16_test['labels'] = rest16_test['labels'].apply(eval)\n",
        "l_test=rest16_test['labels'].tolist()\n",
        "max_len_test=max(len(i) for i in l_test)\n",
        "print(max_len_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83\n",
            "98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i91zqtrfabcv"
      },
      "source": [
        "## Define classes / functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9oPPLf6abPy"
      },
      "source": [
        "class CustomBertTokenClassifierLinear(nn.Module):\n",
        "    def __init__(self, bert, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        \"\"\"uncomment below for Bert-linear\"\"\"\n",
        "        self.fc = nn.Linear(self.embedding_dim, num_labels)\n",
        "\n",
        "        '''OR uncomment below for Bert-Gru'''\n",
        "        # self.gru = nn.GRU(input_size=self.embedding_dim, hidden_size=256, batch_first=True)\n",
        "        # self.fc = nn.Linear(256, num_labels)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # text = [batch size, sent len]\n",
        "        bert_outs = self.bert(input_ids, attention_mask)  # outputs = {last_hidden_state, hidden_states}\n",
        "        embedding = bert_outs.last_hidden_state  # embedding = [batch size, sent len, emb dim=768]\n",
        "        #all_hidden = bert_outs.hidden_states  # all_hidden = tuple of tensors size=13, each tensor = [batch size, sent_len, hidden_dim=768]\n",
        "        #print('embedding:', embedding.shape)\n",
        "        #print('all_hidden:', f\"Tuple length:{len(all_hidden)}\", [t.shape for t in all_hidden])\n",
        "        dropped = self.dropout(embedding)\n",
        "\n",
        "        \"\"\"uncomment below for Bert-linear\"\"\"\n",
        "        logits = self.fc(dropped) # output = [batch size, sent len, output dim]\n",
        "        \n",
        "        '''OR uncomment below for Bert-Gru'''\n",
        "        # output,h_n = self.gru(dropped)\n",
        "        # logits = self.fc(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # print(labels.size())\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            # Only keep active parts of the loss\n",
        "            if attention_mask is not None:\n",
        "                active_loss = attention_mask.view(-1) == 1\n",
        "                active_logits = logits.view(-1, self.num_labels)\n",
        "                active_labels = torch.where(\n",
        "                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
        "                )\n",
        "                loss = loss_fct(active_logits, active_labels)\n",
        "            else:\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        \n",
        "        return logits, loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhSF1KfxmaBc"
      },
      "source": [
        "class CustomBertTokenClassifierGRU(nn.Module):\n",
        "    def __init__(self, bert, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        \"\"\"uncomment below for Bert-linear\"\"\"\n",
        "        # self.fc = nn.Linear(self.embedding_dim, num_labels)\n",
        "\n",
        "        '''OR uncomment below for Bert-Gru'''\n",
        "        self.gru = nn.GRU(input_size=self.embedding_dim, hidden_size=256, batch_first=True)\n",
        "        self.fc = nn.Linear(256, num_labels)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # text = [batch size, sent len]\n",
        "        bert_outs = self.bert(input_ids, attention_mask)  # outputs = {last_hidden_state, hidden_states}\n",
        "        embedding = bert_outs.last_hidden_state  # embedding = [batch size, sent len, emb dim=768]\n",
        "        #all_hidden = bert_outs.hidden_states  # all_hidden = tuple of tensors size=13, each tensor = [batch size, sent_len, hidden_dim=768]\n",
        "        #print('embedding:', embedding.shape)\n",
        "        #print('all_hidden:', f\"Tuple length:{len(all_hidden)}\", [t.shape for t in all_hidden])\n",
        "        dropped = self.dropout(embedding)\n",
        "\n",
        "        \"\"\"uncomment below for Bert-linear\"\"\"\n",
        "        # logits = self.fc(dropped) # output = [batch size, sent len, output dim]\n",
        "        \n",
        "        '''OR uncomment below for Bert-Gru'''\n",
        "        output,h_n = self.gru(dropped)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            # print(labels.size())\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            # Only keep active parts of the loss\n",
        "            if attention_mask is not None:\n",
        "                active_loss = attention_mask.view(-1) == 1\n",
        "                active_logits = logits.view(-1, self.num_labels)\n",
        "                active_labels = torch.where(\n",
        "                    active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
        "                )\n",
        "                loss = loss_fct(active_logits, active_labels)\n",
        "            else:\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "        \n",
        "        return logits, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7kw-M3XmQxo"
      },
      "source": [
        "# Sample code for training the pytorch model\n",
        "def train_model(epochs, model, optimizer, train_dataloader):\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits, loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "            #label_ids = b_labels.to('cpu').numpy()\n",
        "            total_loss += loss.item()\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f'Loss = {total_loss / len(train_dataloader)}')\n",
        "        \n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            _, loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        #label_ids = b_labels.to('cpu').numpy()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Loss = {total_loss / len(val_dataloader)}')\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKIgL3jioMg5"
      },
      "source": [
        "def evaluate_prob(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_pred = []\n",
        "    for step, batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            logits, loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        #all_logits.append(logits)\n",
        "        #label_ids = b_labels.to('cpu').numpy()\n",
        "        logits = logits.cpu().numpy()\n",
        "        all_pred.append(np.argmax(logits,axis=2))\n",
        "        # all_logits.append((np.argmax(logits,axis=2),b_labels.cpu().numpy()))\n",
        "        total_loss += loss.item()\n",
        "    print(f'Loss = {total_loss / len(val_dataloader)}')\n",
        "    return np.concatenate(all_pred, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu2V2Vindc9W"
      },
      "source": [
        "## Restaurant-14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4zQJHM7dwQa"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oRDq_imojAC"
      },
      "source": [
        "# Simple output mapping:\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "# label_mapping = {'O': 0, 'B-pos': 1, 'B-neg': 2, 'B-neu': 3, 'I-pos': 4, 'I-neg': 5, 'I-neu': 6}\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant/laptop data '''\n",
        "label_mapping = {'O': 0, 'B-pos': 1, 'B-neg': 2, 'B-neu': 3, 'B-con': 4, 'I-pos': 5, 'I-neg': 6, 'I-neu': 7, 'I-con': 8}\n",
        "\n",
        "\n",
        "def generate_input_masks_labels(df, MAX_LEN):\n",
        "    input_ids  = list(df['token_ids'])\n",
        "    attention_masks = [torch.ones((len(x)), dtype=torch.long) for x in input_ids]\n",
        "    labels = [[label_mapping[x] for x in seq] for seq in df['labels']]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    attention_masks = pad_sequences(attention_masks, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    labels = pad_sequences(labels, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    input_ids = torch.tensor(input_ids).long()\n",
        "    attention_masks = torch.tensor(attention_masks).long()\n",
        "    labels = torch.tensor(labels).long()\n",
        "    return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.434840Z",
          "start_time": "2021-07-26T15:00:30.371991Z"
        },
        "id": "PGfYRSayJBFO"
      },
      "source": [
        "input_ids, attention_masks, labels = generate_input_masks_labels(rest14_train, 100)\n",
        "\n",
        "batch_size = 10\n",
        "train_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.480719Z",
          "start_time": "2021-07-26T15:00:30.452793Z"
        },
        "id": "0Qaj2cpVsfEX"
      },
      "source": [
        "input_ids_test, attention_masks_test, labels_test = generate_input_masks_labels(rest14_test, 100)\n",
        "\n",
        "test_batch_size = 10\n",
        "test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DCuu7Ovp0wO"
      },
      "source": [
        "### Linear, 3 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KemH2y4OrIRy"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:11.108050Z",
          "start_time": "2021-07-26T15:00:30.481714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHD-M2XlLoRr",
        "outputId": "3b5f66a7-1a67-4979-955e-2426dae5ca98"
      },
      "source": [
        "pred_log = []\n",
        "epochs = 3\n",
        "num_labels = len(label_mapping)\n",
        "#num_labels = 3\n",
        "bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = CustomBertTokenClassifierLinear(bert, num_labels)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.05},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
        "for ep in range(epochs):\n",
        "    print(f\"=== Training phase {ep+1} ====\")\n",
        "    train_model(1, model, optimizer, train_dataloader)\n",
        "    print(f\"=== Eval phase {ep+1} ====\")\n",
        "    evaluate(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 2/305 [00:00<00:23, 13.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== Training phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:22<00:00, 13.81it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 49.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.302656863635925\n",
            "=== Eval phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 48.87it/s]\n",
            "  1%|          | 2/305 [00:00<00:21, 13.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.17548350755823777\n",
            "=== Training phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:22<00:00, 13.82it/s]\n",
            "  8%|▊         | 6/80 [00:00<00:01, 50.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.16225250835423588\n",
            "=== Eval phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 49.45it/s]\n",
            "  1%|          | 2/305 [00:00<00:21, 13.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.13107971445424482\n",
            "=== Training phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:22<00:00, 13.83it/s]\n",
            "  8%|▊         | 6/80 [00:00<00:01, 50.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.11314320065172725\n",
            "=== Eval phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 49.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.11376870670937933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:14.750306Z",
          "start_time": "2021-07-26T15:04:11.125004Z"
        },
        "id": "0g3He_LPsfEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e185976e-63ef-4ec0-986b-fa29b61517bf"
      },
      "source": [
        "pred = evaluate_prob(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 48.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.11376870670937933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzoQzzY1YuLV",
        "outputId": "667a0fd8-2aa5-4a1f-c28f-7ef1a451cb22"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#all_pred = np.concatenate(pred, axis=0)\n",
        "#print(pred.shape)\n",
        "test_labels_np = labels_test.cpu().numpy().flatten()\n",
        "pred = pred.flatten()\n",
        "\n",
        "att_mask = attention_masks_test.cpu().numpy().flatten() == 1\n",
        "test_labels_final = test_labels_np[att_mask]\n",
        "pred_final = pred[att_mask]\n",
        "\n",
        "#print(test_labels_np.shape)\n",
        "pd.DataFrame(confusion_matrix(test_labels_final, pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13115</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52</td>\n",
              "      <td>637</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>124</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>41</td>\n",
              "      <td>11</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>51</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>626</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "      <td>12</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2    3  4    5   6   7  8\n",
              "0  13115   19    9    9  0   44   4  11  0\n",
              "1     52  637    8   16  0   15   0   0  0\n",
              "2     21   24  124   23  0    1   0   2  0\n",
              "3     22   41   11  116  0    4   0   1  0\n",
              "4      0   10    3    1  0    0   0   0  0\n",
              "5     51   15    0    1  0  626   4   6  0\n",
              "6     12    1    2    1  0   26  65  11  0\n",
              "7     24    3    1    2  0  103  12  99  0\n",
              "8      0    0    0    0  0    2   0   0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpSlAar1rKWY"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOnZAV_VcVHu",
        "outputId": "39c323a1-50ca-4bbc-e8b5-2c070411bac6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "# print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6], target_names=[\"B-pos\",'B-neg','B-neu','I-pos','I-neg','I-neu']))\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant data '''\n",
        "print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6,7,8], target_names=[\"B-pos\",'B-neg','B-neu','B-con','I-pos','I-neg','I-neu','I-con']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-pos       0.85      0.88      0.86       728\n",
            "       B-neg       0.78      0.64      0.70       195\n",
            "       B-neu       0.69      0.59      0.64       195\n",
            "       B-con       0.00      0.00      0.00        14\n",
            "       I-pos       0.76      0.89      0.82       703\n",
            "       I-neg       0.76      0.55      0.64       118\n",
            "       I-neu       0.76      0.41      0.53       244\n",
            "       I-con       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.79      0.76      0.77      2199\n",
            "   macro avg       0.58      0.49      0.52      2199\n",
            "weighted avg       0.78      0.76      0.76      2199\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KgwKJE9pDMg",
        "outputId": "15efbf11-b0c3-4eac-931c-275e5b1ab953"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "micro_precision = precision_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_recall = recall_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_f1 = f1_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "print(f'micro_precision: {micro_precision:.3f}')\n",
        "print(f'micro_recall: {micro_recall:.3f}')\n",
        "print(f'micro_f1: {micro_f1:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro_precision: 0.789\n",
            "micro_recall: 0.758\n",
            "micro_f1: 0.773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB44XNW5qYwU"
      },
      "source": [
        "### GRU, 5 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF3WD-NSsT4A"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:11.108050Z",
          "start_time": "2021-07-26T15:00:30.481714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BpmEBmCqaKI",
        "outputId": "5c16c1fe-3fe0-44a2-80ec-183a7cbb66a1"
      },
      "source": [
        "pred_log = []\n",
        "epochs = 5\n",
        "num_labels = len(label_mapping)\n",
        "#num_labels = 3\n",
        "bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = CustomBertTokenClassifierGRU(bert, num_labels)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.05},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
        "for ep in range(epochs):\n",
        "    print(f\"=== Training phase {ep+1} ====\")\n",
        "    train_model(1, model, optimizer, train_dataloader)\n",
        "    print(f\"=== Eval phase {ep+1} ====\")\n",
        "    evaluate(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 2/305 [00:00<00:22, 13.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== Training phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.83it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 43.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.34529461099720393\n",
            "=== Eval phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.42it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 13.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.20572028018068522\n",
            "=== Training phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.87it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 43.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1729907085783169\n",
            "=== Eval phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.54it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 13.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1754452728317119\n",
            "=== Training phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.88it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 44.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.13565689369913986\n",
            "=== Eval phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.50it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 12.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.18671674370998517\n",
            "=== Training phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.81it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 42.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.10397010206237252\n",
            "=== Eval phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 42.11it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 12.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.17748159288894386\n",
            "=== Training phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.76it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 44.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.08091730241526346\n",
            "=== Eval phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 42.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1732613062951714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:14.750306Z",
          "start_time": "2021-07-26T15:04:11.125004Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv_rdO4iqaKJ",
        "outputId": "279c7d35-a4f0-44b6-ba82-51e05ba0b73c"
      },
      "source": [
        "pred = evaluate_prob(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 42.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1732613062951714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "qVdErtz0qaKJ",
        "outputId": "7d977a6c-def1-4a13-b18c-f14785cacb7e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#all_pred = np.concatenate(pred, axis=0)\n",
        "#print(pred.shape)\n",
        "test_labels_np = labels_test.cpu().numpy().flatten()\n",
        "pred = pred.flatten()\n",
        "\n",
        "att_mask = attention_masks_test.cpu().numpy().flatten() == 1\n",
        "test_labels_final = test_labels_np[att_mask]\n",
        "pred_final = pred[att_mask]\n",
        "\n",
        "#print(test_labels_np.shape)\n",
        "pd.DataFrame(confusion_matrix(test_labels_final, pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13108</td>\n",
              "      <td>27</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>636</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>164</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>71</td>\n",
              "      <td>59</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>47</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>607</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>71</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>26</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2   3  4    5   6   7  8\n",
              "0  13108   27   15   8  0   42   5   6  0\n",
              "1     45  636   30   6  0   11   0   0  0\n",
              "2     22    6  164   3  0    0   0   0  0\n",
              "3     19   71   59  44  0    2   0   0  0\n",
              "4      0    9    5   0  0    0   0   0  0\n",
              "5     47   21    4   0  0  607  17   7  0\n",
              "6     21    0    7   0  0   14  71   5  0\n",
              "7     21    7    1   3  0  152  26  34  0\n",
              "8      0    0    0   0  0    1   1   0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TofsQAf6sWDS"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osXTEQj-qaKJ",
        "outputId": "66820ded-f4a0-49c3-cad3-45d19c6d1e36"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "# print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6], target_names=[\"B-pos\",'B-neg','B-neu','I-pos','I-neg','I-neu']))\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant data '''\n",
        "print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6,7,8], target_names=[\"B-pos\",'B-neg','B-neu','B-con','I-pos','I-neg','I-neu','I-con']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-pos       0.82      0.87      0.85       728\n",
            "       B-neg       0.58      0.84      0.68       195\n",
            "       B-neu       0.69      0.23      0.34       195\n",
            "       B-con       0.00      0.00      0.00        14\n",
            "       I-pos       0.73      0.86      0.79       703\n",
            "       I-neg       0.59      0.60      0.60       118\n",
            "       I-neu       0.65      0.14      0.23       244\n",
            "       I-con       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.73      0.71      0.72      2199\n",
            "   macro avg       0.51      0.44      0.44      2199\n",
            "weighted avg       0.72      0.71      0.68      2199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTe3sc-7qaKJ",
        "outputId": "dab8bb6b-489c-4a8f-bc8e-835ffd3015cf"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "micro_precision = precision_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_recall = recall_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_f1 = f1_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "print(f'micro_precision: {micro_precision:.3f}')\n",
        "print(f'micro_recall: {micro_recall:.3f}')\n",
        "print(f'micro_f1: {micro_f1:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro_precision: 0.732\n",
            "micro_recall: 0.708\n",
            "micro_f1: 0.719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBlkWm-Psk1m"
      },
      "source": [
        "## Laptops-14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXHy_daKsk1m"
      },
      "source": [
        "# Simple output mapping:\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "# label_mapping = {'O': 0, 'B-pos': 1, 'B-neg': 2, 'B-neu': 3, 'I-pos': 4, 'I-neg': 5, 'I-neu': 6}\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant/laptop data '''\n",
        "label_mapping = {'O': 0, 'B-pos': 1, 'B-neg': 2, 'B-neu': 3, 'B-con': 4, 'I-pos': 5, 'I-neg': 6, 'I-neu': 7, 'I-con': 8}\n",
        "\n",
        "\n",
        "def generate_input_masks_labels(df, MAX_LEN):\n",
        "    input_ids  = list(df['token_ids'])\n",
        "    attention_masks = [torch.ones((len(x)), dtype=torch.long) for x in input_ids]\n",
        "    labels = [[label_mapping[x] for x in seq] for seq in df['labels']]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    attention_masks = pad_sequences(attention_masks, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    labels = pad_sequences(labels, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    input_ids = torch.tensor(input_ids).long()\n",
        "    attention_masks = torch.tensor(attention_masks).long()\n",
        "    labels = torch.tensor(labels).long()\n",
        "    return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.434840Z",
          "start_time": "2021-07-26T15:00:30.371991Z"
        },
        "id": "fEE3oNe-sk1m"
      },
      "source": [
        "input_ids, attention_masks, labels = generate_input_masks_labels(lap14_train, 100)\n",
        "\n",
        "batch_size = 10\n",
        "train_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.480719Z",
          "start_time": "2021-07-26T15:00:30.452793Z"
        },
        "id": "qo4S2y1Msk1m"
      },
      "source": [
        "input_ids_test, attention_masks_test, labels_test = generate_input_masks_labels(lap14_test, 100)\n",
        "\n",
        "test_batch_size = 10\n",
        "test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GOQdVQVsk1m"
      },
      "source": [
        "### Linear, 3 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy6vrH5-sk1m"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:11.108050Z",
          "start_time": "2021-07-26T15:00:30.481714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X946YQsWsk1m",
        "outputId": "2805a887-9502-4ee4-be05-3218a73d49b5"
      },
      "source": [
        "pred_log = []\n",
        "epochs = 3\n",
        "num_labels = len(label_mapping)\n",
        "#num_labels = 3\n",
        "bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = CustomBertTokenClassifierLinear(bert, num_labels)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.05},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
        "for ep in range(epochs):\n",
        "    print(f\"=== Training phase {ep+1} ====\")\n",
        "    train_model(1, model, optimizer, train_dataloader)\n",
        "    print(f\"=== Eval phase {ep+1} ====\")\n",
        "    evaluate(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 2/305 [00:00<00:26, 11.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== Training phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:22<00:00, 13.78it/s]\n",
            "  8%|▊         | 6/80 [00:00<00:01, 50.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.22254130876638362\n",
            "=== Eval phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 49.10it/s]\n",
            "  1%|          | 2/305 [00:00<00:22, 13.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.15025797667913138\n",
            "=== Training phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:22<00:00, 13.75it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 49.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.12112832844532172\n",
            "=== Eval phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 49.17it/s]\n",
            "  1%|          | 2/305 [00:00<00:21, 13.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.12612104575964622\n",
            "=== Training phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:22<00:00, 13.81it/s]\n",
            "  8%|▊         | 6/80 [00:00<00:01, 50.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.08421014273752932\n",
            "=== Eval phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 49.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.11161646461114287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:14.750306Z",
          "start_time": "2021-07-26T15:04:11.125004Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lADJkEbsk1n",
        "outputId": "1f31a690-6b8f-4e2e-c504-66c525db660f"
      },
      "source": [
        "pred = evaluate_prob(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 49.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.11161646461114287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "P-6-6qzVsk1n",
        "outputId": "10ad3b65-5f28-4cd9-9b58-aa28e1b3f4e6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#all_pred = np.concatenate(pred, axis=0)\n",
        "#print(pred.shape)\n",
        "test_labels_np = labels_test.cpu().numpy().flatten()\n",
        "pred = pred.flatten()\n",
        "\n",
        "att_mask = attention_masks_test.cpu().numpy().flatten() == 1\n",
        "test_labels_final = test_labels_np[att_mask]\n",
        "pred_final = pred[att_mask]\n",
        "\n",
        "#print(test_labels_np.shape)\n",
        "pd.DataFrame(confusion_matrix(test_labels_final, pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12637</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>46</td>\n",
              "      <td>258</td>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>72</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>38</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>16</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>66</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>28</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1   2    3  4    5   6    7  8\n",
              "0  12637   13   1   13  0    1   1   10  0\n",
              "1     46  258  11   25  0    1   0    0  0\n",
              "2     21   13  72   21  0    0   0    1  0\n",
              "3     24   20  18  107  0    0   0    0  0\n",
              "4      1   10   5    0  0    0   0    0  0\n",
              "5     38   11   0    2  0  130  16   29  0\n",
              "6     15    1   3    3  0    5  66   26  0\n",
              "7     31    1   3   11  0    6  28  161  0\n",
              "8      0    0   0    0  0    4   1    0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6GtytmTsk1n"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSVjklyRsk1n",
        "outputId": "d3521317-15db-40c3-b623-43336ad9050b"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "# print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6], target_names=[\"B-pos\",'B-neg','B-neu','I-pos','I-neg','I-neu']))\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant data '''\n",
        "print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6,7,8], target_names=[\"B-pos\",'B-neg','B-neu','B-con','I-pos','I-neg','I-neu','I-con']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-pos       0.79      0.76      0.77       341\n",
            "       B-neg       0.64      0.56      0.60       128\n",
            "       B-neu       0.59      0.63      0.61       169\n",
            "       B-con       0.00      0.00      0.00        16\n",
            "       I-pos       0.88      0.58      0.70       226\n",
            "       I-neg       0.59      0.55      0.57       119\n",
            "       I-neu       0.71      0.67      0.69       241\n",
            "       I-con       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.72      0.64      0.67      1245\n",
            "   macro avg       0.52      0.47      0.49      1245\n",
            "weighted avg       0.72      0.64      0.67      1245\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE44KRIusk1n",
        "outputId": "19439bb4-fe97-45f5-c718-628d90c9f62d"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "micro_precision = precision_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_recall = recall_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_f1 = f1_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "print(f'micro_precision: {micro_precision:.3f}')\n",
        "print(f'micro_recall: {micro_recall:.3f}')\n",
        "print(f'micro_f1: {micro_f1:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro_precision: 0.717\n",
            "micro_recall: 0.638\n",
            "micro_f1: 0.675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV_dIsmDsk1p"
      },
      "source": [
        "### GRU, 5 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgzOox1Psk1p"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:11.108050Z",
          "start_time": "2021-07-26T15:00:30.481714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPEMTk2jsk1p",
        "outputId": "693b4f99-1d48-47f7-d4c7-bccd8c21b526"
      },
      "source": [
        "pred_log = []\n",
        "epochs = 5\n",
        "num_labels = len(label_mapping)\n",
        "#num_labels = 3\n",
        "bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = CustomBertTokenClassifierGRU(bert, num_labels)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.05},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
        "for ep in range(epochs):\n",
        "    print(f\"=== Training phase {ep+1} ====\")\n",
        "    train_model(1, model, optimizer, train_dataloader)\n",
        "    print(f\"=== Eval phase {ep+1} ====\")\n",
        "    evaluate(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 2/305 [00:00<00:29, 10.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== Training phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.83it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 43.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.31989542898096024\n",
            "=== Eval phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.40it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 13.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.2080003712559119\n",
            "=== Training phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.80it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 44.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.16523960487397968\n",
            "=== Eval phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.09it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 12.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.16851402504835278\n",
            "=== Training phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.81it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 44.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.12176911494099214\n",
            "=== Eval phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.26it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 13.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.13858057105680927\n",
            "=== Training phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.81it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 43.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.09230624371681545\n",
            "=== Eval phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.33it/s]\n",
            "  1%|          | 2/305 [00:00<00:23, 13.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.16929568868363276\n",
            "=== Training phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 305/305 [00:23<00:00, 12.80it/s]\n",
            "  6%|▋         | 5/80 [00:00<00:01, 43.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.08224186900331348\n",
            "=== Eval phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 43.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.13648305323440582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:14.750306Z",
          "start_time": "2021-07-26T15:04:11.125004Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk1IOBu9sk1p",
        "outputId": "6d9851da-883a-4114-a83a-95e797f35b4d"
      },
      "source": [
        "pred = evaluate_prob(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [00:01<00:00, 42.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.13648305323440582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW_1n0eTsk1q",
        "outputId": "9b79696e-d8aa-46c2-bf05-c8ea03e35647"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#all_pred = np.concatenate(pred, axis=0)\n",
        "#print(pred.shape)\n",
        "test_labels_np = labels_test.cpu().numpy().flatten()\n",
        "pred = pred.flatten()\n",
        "\n",
        "att_mask = attention_masks_test.cpu().numpy().flatten() == 1\n",
        "test_labels_final = test_labels_np[att_mask]\n",
        "pred_final = pred[att_mask]\n",
        "\n",
        "#print(test_labels_np.shape)\n",
        "pd.DataFrame(confusion_matrix(test_labels_final, pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12573</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>269</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>92</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>23</td>\n",
              "      <td>41</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>33</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>13</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>75</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>55</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1   2   3  4    5   6    7  8\n",
              "0  12573   29  13  24  0   11   5   21  0\n",
              "1     35  269  13  20  0    3   0    1  0\n",
              "2     13    9  92  11  0    1   1    1  0\n",
              "3     12   23  41  92  0    0   1    0  0\n",
              "4      0   11   4   1  0    0   0    0  0\n",
              "5     33    8   1   4  0  141  13   26  0\n",
              "6     18    0   2   3  0    9  75   12  0\n",
              "7     25    1   2   8  0   10  55  140  0\n",
              "8      0    0   0   0  0    2   1    2  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REl38L_esk1q"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfCgDesOsk1q",
        "outputId": "3c1e9197-e7d8-4dfc-ddd9-8fae1598c763"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "# print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6], target_names=[\"B-pos\",'B-neg','B-neu','I-pos','I-neg','I-neu']))\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant data '''\n",
        "print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6,7,8], target_names=[\"B-pos\",'B-neg','B-neu','B-con','I-pos','I-neg','I-neu','I-con']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-pos       0.77      0.79      0.78       341\n",
            "       B-neg       0.55      0.72      0.62       128\n",
            "       B-neu       0.56      0.54      0.55       169\n",
            "       B-con       0.00      0.00      0.00        16\n",
            "       I-pos       0.80      0.62      0.70       226\n",
            "       I-neg       0.50      0.63      0.56       119\n",
            "       I-neu       0.69      0.58      0.63       241\n",
            "       I-con       0.00      0.00      0.00         5\n",
            "\n",
            "   micro avg       0.67      0.65      0.66      1245\n",
            "   macro avg       0.48      0.49      0.48      1245\n",
            "weighted avg       0.67      0.65      0.65      1245\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTCT0vIIsk1s",
        "outputId": "88cf67af-50f3-4083-f103-bbad2912155a"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "micro_precision = precision_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_recall = recall_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "micro_f1 = f1_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6,7,8], average='micro')\n",
        "print(f'micro_precision: {micro_precision:.3f}')\n",
        "print(f'micro_recall: {micro_recall:.3f}')\n",
        "print(f'micro_f1: {micro_f1:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro_precision: 0.667\n",
            "micro_recall: 0.650\n",
            "micro_f1: 0.659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM4ur4sTsk1s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQE7lSsMuk9O"
      },
      "source": [
        "## Restaurants-16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IKYlfW3uk9P"
      },
      "source": [
        "# Simple output mapping:\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "label_mapping = {'O': 0, 'B-pos': 1, 'B-neg': 2, 'B-neu': 3, 'I-pos': 4, 'I-neg': 5, 'I-neu': 6}\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant/laptop data '''\n",
        "# label_mapping = {'O': 0, 'B-pos': 1, 'B-neg': 2, 'B-neu': 3, 'B-con': 4, 'I-pos': 5, 'I-neg': 6, 'I-neu': 7, 'I-con': 8}\n",
        "\n",
        "\n",
        "def generate_input_masks_labels(df, MAX_LEN):\n",
        "    input_ids  = list(df['token_ids'])\n",
        "    attention_masks = [torch.ones((len(x)), dtype=torch.long) for x in input_ids]\n",
        "    labels = [[label_mapping[x] for x in seq] for seq in df['labels']]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    attention_masks = pad_sequences(attention_masks, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    labels = pad_sequences(labels, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\", value=0)\n",
        "    input_ids = torch.tensor(input_ids).long()\n",
        "    attention_masks = torch.tensor(attention_masks).long()\n",
        "    labels = torch.tensor(labels).long()\n",
        "    return input_ids, attention_masks, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.434840Z",
          "start_time": "2021-07-26T15:00:30.371991Z"
        },
        "id": "HzcMATZDuk9P"
      },
      "source": [
        "input_ids, attention_masks, labels = generate_input_masks_labels(rest16_train, 100)\n",
        "\n",
        "batch_size = 10\n",
        "train_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:00:30.480719Z",
          "start_time": "2021-07-26T15:00:30.452793Z"
        },
        "id": "dgHlgBKQuk9Q"
      },
      "source": [
        "input_ids_test, attention_masks_test, labels_test = generate_input_masks_labels(rest16_test, 100)\n",
        "\n",
        "test_batch_size = 10\n",
        "test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxt3YylIuk9T"
      },
      "source": [
        "### Linear, 5 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MMCVDMFuk9U"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:11.108050Z",
          "start_time": "2021-07-26T15:00:30.481714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVd9Oojouk9U",
        "outputId": "f9b4da22-540e-406d-bf87-78aae9872cbf"
      },
      "source": [
        "pred_log = []\n",
        "epochs = 5\n",
        "num_labels = len(label_mapping)\n",
        "#num_labels = 3\n",
        "bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = CustomBertTokenClassifierLinear(bert, num_labels)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.05},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
        "for ep in range(epochs):\n",
        "    print(f\"=== Training phase {ep+1} ====\")\n",
        "    train_model(1, model, optimizer, train_dataloader)\n",
        "    print(f\"=== Eval phase {ep+1} ====\")\n",
        "    evaluate(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 2/200 [00:00<00:14, 14.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== Training phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:14<00:00, 13.79it/s]\n",
            "  9%|▉         | 6/68 [00:00<00:01, 50.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.2649430753290653\n",
            "=== Eval phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 50.00it/s]\n",
            "  1%|          | 2/200 [00:00<00:14, 13.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.15637477952986956\n",
            "=== Training phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:14<00:00, 13.83it/s]\n",
            "  9%|▉         | 6/68 [00:00<00:01, 50.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.12279128772206604\n",
            "=== Eval phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 49.84it/s]\n",
            "  1%|          | 2/200 [00:00<00:14, 14.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.16985366991995013\n",
            "=== Training phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:14<00:00, 13.85it/s]\n",
            "  9%|▉         | 6/68 [00:00<00:01, 50.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.08110550518613309\n",
            "=== Eval phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 49.97it/s]\n",
            "  1%|          | 2/200 [00:00<00:14, 13.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1659327730851467\n",
            "=== Training phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:14<00:00, 13.74it/s]\n",
            "  7%|▋         | 5/68 [00:00<00:01, 48.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.06300255735171958\n",
            "=== Eval phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 49.34it/s]\n",
            "  1%|          | 2/200 [00:00<00:14, 13.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1734730192042394\n",
            "=== Training phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:14<00:00, 13.71it/s]\n",
            "  9%|▉         | 6/68 [00:00<00:01, 50.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.039921687602763996\n",
            "=== Eval phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 49.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.15763524018556757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:14.750306Z",
          "start_time": "2021-07-26T15:04:11.125004Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8tn438Puk9U",
        "outputId": "8b586258-bd2c-4d01-ff45-c822fc2b06af"
      },
      "source": [
        "pred = evaluate_prob(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 49.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.15763524018556757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSbPhuMcuk9V",
        "outputId": "1df80808-a4b9-48d9-ee4a-ec244f7b3191"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#all_pred = np.concatenate(pred, axis=0)\n",
        "#print(pred.shape)\n",
        "test_labels_np = labels_test.cpu().numpy().flatten()\n",
        "pred = pred.flatten()\n",
        "\n",
        "att_mask = attention_masks_test.cpu().numpy().flatten() == 1\n",
        "test_labels_final = test_labels_np[att_mask]\n",
        "pred_final = pred[att_mask]\n",
        "\n",
        "#print(test_labels_np.shape)\n",
        "pd.DataFrame(confusion_matrix(test_labels_final, pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10944</td>\n",
              "      <td>54</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>91</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73</td>\n",
              "      <td>373</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>109</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>398</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1   2  3    4   5  6\n",
              "0  10944   54  40  0   91  21  0\n",
              "1     73  373   8  5    9   0  0\n",
              "2     34    3  77  0    1   0  0\n",
              "3      7    5  14  4    0   0  0\n",
              "4    109    9   0  0  398   7  4\n",
              "5     18    0   0  0    6  19  5\n",
              "6     11    0   0  0    3   0  6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDT8AbV6uk9V"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "3pK6EYd7uk9V",
        "outputId": "4e2739f6-c3b9-4bd6-a770-7f0cec0a9e75"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6], target_names=[\"B-pos\",'B-neg','B-neu','I-pos','I-neg','I-neu']))\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant data '''\n",
        "# print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6,7,8], target_names=[\"B-pos\",'B-neg','B-neu','B-con','I-pos','I-neg','I-neu','I-con']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-pos       0.84      0.80      0.82       468\n",
            "       B-neg       0.55      0.67      0.61       115\n",
            "       B-neu       0.44      0.13      0.21        30\n",
            "       I-pos       0.78      0.76      0.77       527\n",
            "       I-neg       0.40      0.40      0.40        48\n",
            "       I-neu       0.40      0.30      0.34        20\n",
            "\n",
            "   micro avg       0.75      0.73      0.74      1208\n",
            "   macro avg       0.57      0.51      0.52      1208\n",
            "weighted avg       0.75      0.73      0.74      1208\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'OR Uncomment below for 14 restaurant data '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw1JqDiluk9V",
        "outputId": "7f3f54a3-ded9-4608-ce5b-d92288894686"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "micro_precision = precision_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6], average='micro')\n",
        "micro_recall = recall_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6], average='micro')\n",
        "micro_f1 = f1_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6], average='micro')\n",
        "print(f'micro_precision: {micro_precision:.3f}')\n",
        "print(f'micro_recall: {micro_recall:.3f}')\n",
        "print(f'micro_f1: {micro_f1:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro_precision: 0.755\n",
            "micro_recall: 0.726\n",
            "micro_f1: 0.740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyA6l1Byuk9Y"
      },
      "source": [
        "### GRU, 5 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbfYuQPruk9Y"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:11.108050Z",
          "start_time": "2021-07-26T15:00:30.481714Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBru7wqeuk9Y",
        "outputId": "caeb8d6d-72ee-4e32-92be-9790f89b9543"
      },
      "source": [
        "pred_log = []\n",
        "epochs = 5\n",
        "num_labels = len(label_mapping)\n",
        "#num_labels = 3\n",
        "bert = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "model = CustomBertTokenClassifierGRU(bert, num_labels)\n",
        "model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.05},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "    'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5)\n",
        "for ep in range(epochs):\n",
        "    print(f\"=== Training phase {ep+1} ====\")\n",
        "    train_model(1, model, optimizer, train_dataloader)\n",
        "    print(f\"=== Eval phase {ep+1} ====\")\n",
        "    evaluate(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  1%|          | 2/200 [00:00<00:15, 12.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== Training phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.83it/s]\n",
            "  7%|▋         | 5/68 [00:00<00:01, 43.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.3938207312300801\n",
            "=== Eval phase 1 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 43.37it/s]\n",
            "  1%|          | 2/200 [00:00<00:15, 13.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.21254135629929163\n",
            "=== Training phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.86it/s]\n",
            "  7%|▋         | 5/68 [00:00<00:01, 44.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1934179037064314\n",
            "=== Eval phase 2 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 43.69it/s]\n",
            "  1%|          | 2/200 [00:00<00:14, 13.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.1823943656157045\n",
            "=== Training phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.84it/s]\n",
            "  7%|▋         | 5/68 [00:00<00:01, 42.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.13276214151643217\n",
            "=== Eval phase 3 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 43.44it/s]\n",
            "  1%|          | 2/200 [00:00<00:15, 13.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.19774929699761903\n",
            "=== Training phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.80it/s]\n",
            "  7%|▋         | 5/68 [00:00<00:01, 44.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.09687226405367255\n",
            "=== Eval phase 4 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 43.61it/s]\n",
            "  1%|          | 2/200 [00:00<00:15, 13.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.17575550712097218\n",
            "=== Training phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.83it/s]\n",
            "  7%|▋         | 5/68 [00:00<00:01, 44.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.08105004204902798\n",
            "=== Eval phase 5 ====\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 43.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.19440187497393174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-07-26T15:04:14.750306Z",
          "start_time": "2021-07-26T15:04:11.125004Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUR5vRrHuk9Y",
        "outputId": "a497f5b5-f0a7-40be-9128-957dd0f406e1"
      },
      "source": [
        "pred = evaluate_prob(model,test_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 68/68 [00:01<00:00, 43.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss = 0.19440187497393174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jYRITuLuk9Z",
        "outputId": "1f174e43-8dba-41c9-8338-5d88bf4dbb03"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#all_pred = np.concatenate(pred, axis=0)\n",
        "#print(pred.shape)\n",
        "test_labels_np = labels_test.cpu().numpy().flatten()\n",
        "pred = pred.flatten()\n",
        "\n",
        "att_mask = attention_masks_test.cpu().numpy().flatten() == 1\n",
        "test_labels_final = test_labels_np[att_mask]\n",
        "pred_final = pred[att_mask]\n",
        "\n",
        "#print(test_labels_np.shape)\n",
        "pd.DataFrame(confusion_matrix(test_labels_final, pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10798</td>\n",
              "      <td>130</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>403</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>19</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>410</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1   2  3    4   5  6\n",
              "0  10798  130  53  0  122  47  0\n",
              "1     35  403  15  0   15   0  0\n",
              "2     22   19  72  0    0   2  0\n",
              "3      6   13  11  0    0   0  0\n",
              "4     88   18   1  0  410  10  0\n",
              "5     12    0   2  0   10  24  0\n",
              "6     11    0   1  0    6   2  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBz1Xdjtuk9Z"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "eNAeMnXiuk9Z",
        "outputId": "bbb3c14d-61ce-4c88-b561-e6ee4bbce60a"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "'''Uncomment below for 16 restaurant data '''\n",
        "print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6], target_names=[\"B-pos\",'B-neg','B-neu','I-pos','I-neg','I-neu']))\n",
        "\n",
        "'''OR Uncomment below for 14 restaurant data '''\n",
        "# print(classification_report(test_labels_final,pred_final,labels=[1,2,3,4,5,6,7,8], target_names=[\"B-pos\",'B-neg','B-neu','B-con','I-pos','I-neg','I-neu','I-con']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-pos       0.69      0.86      0.77       468\n",
            "       B-neg       0.46      0.63      0.53       115\n",
            "       B-neu       0.00      0.00      0.00        30\n",
            "       I-pos       0.73      0.78      0.75       527\n",
            "       I-neg       0.28      0.50      0.36        48\n",
            "       I-neu       0.00      0.00      0.00        20\n",
            "\n",
            "   micro avg       0.66      0.75      0.70      1208\n",
            "   macro avg       0.36      0.46      0.40      1208\n",
            "weighted avg       0.64      0.75      0.69      1208\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'OR Uncomment below for 14 restaurant data '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNZ99sxLuk9Z",
        "outputId": "09496f73-c1f2-47e1-ddcf-98f67d46812b"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "micro_precision = precision_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6], average='micro')\n",
        "micro_recall = recall_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6], average='micro')\n",
        "micro_f1 = f1_score(test_labels_final,pred_final, labels=[1,2,3,4,5,6], average='micro')\n",
        "print(f'micro_precision: {micro_precision:.3f}')\n",
        "print(f'micro_recall: {micro_recall:.3f}')\n",
        "print(f'micro_f1: {micro_f1:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro_precision: 0.656\n",
            "micro_recall: 0.752\n",
            "micro_f1: 0.701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4zcCeROuk9Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}